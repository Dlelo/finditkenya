{
  "_from": "mongoosastic",
  "_id": "mongoosastic@4.4.1",
  "_inBundle": false,
  "_integrity": "sha512-x9wIiI3Jd9TICN75uim3yVPX+vlk1ZpIKP3JJr6rNuULO2JSbGELqHO7RtnhM40Iw/ClXSlRh+dMggaE+EYLjA==",
  "_location": "/mongoosastic",
  "_phantomChildren": {
    "chalk": "1.1.3",
    "lodash.get": "4.4.2",
    "lodash.isempty": "4.4.0",
    "lodash.trimend": "4.5.1"
  },
  "_requested": {
    "escapedName": "mongoosastic",
    "fetchSpec": "latest",
    "name": "mongoosastic",
    "raw": "mongoosastic",
    "rawSpec": "",
    "registry": true,
    "saveSpec": null,
    "type": "tag"
  },
  "_requiredBy": [
    "#USER",
    "/"
  ],
  "_resolved": "https://registry.npmjs.org/mongoosastic/-/mongoosastic-4.4.1.tgz",
  "_shasum": "dd2d5ebdd30e828bf45af8f256dc26851e5820cb",
  "_shrinkwrap": null,
  "_spec": "mongoosastic",
  "_where": "/home/kev/express/findit",
  "author": {
    "email": "james.r.carr@gmail.com",
    "name": "James R. Carr",
    "url": "http://blog.james-carr.org"
  },
  "bugs": {
    "url": "https://github.com/mongoosastic/mongoosastic/issues"
  },
  "bundleDependencies": false,
  "contributors": [
    {
      "name": "James",
      "email": "jdelibas@gmail.com"
    },
    {
      "name": "Alban Mouton",
      "email": "alban.mouton@gmail.com"
    },
    {
      "name": "Andreas Schmid",
      "email": "andreas@nex9.com"
    },
    {
      "name": "antoineverger",
      "email": "antoine.verger@speicher210.com"
    },
    {
      "name": "Antoine Verger",
      "email": "antoine.verger@speicher210.com"
    },
    {
      "name": "Arseny Zarechnev",
      "email": "cyanidesign@gmail.com"
    },
    {
      "name": "Astro",
      "email": "astro@spaceboyz.net"
    },
    {
      "name": "b96705008",
      "email": "b96705008@gmail.com"
    },
    {
      "name": "Bob Lauer",
      "email": "rlauer@gmail.com"
    },
    {
      "name": "Brady Brown",
      "email": "bobrown101@gmail.com"
    },
    {
      "name": "Can Kutlu Kinay",
      "email": "ckkinay@gmail.com"
    },
    {
      "name": "chapel",
      "email": "jacob.chapel@gmail.com"
    },
    {
      "name": "Charlie Tilt",
      "email": "charlie@charlietilt.com"
    },
    {
      "name": "Christian Sturm",
      "email": "reezer@reezer.org"
    },
    {
      "name": "Christophe Wagner",
      "email": "jitowix@gmail.com"
    },
    {
      "name": "cong88",
      "email": "lecong1225@gmail.com"
    },
    {
      "name": "Daniel Rafaj",
      "email": "daniel.rafaj@gmail.com"
    },
    {
      "name": "danteata",
      "email": "danteata@gmail.com"
    },
    {
      "name": "Dan Williams",
      "email": "me@deedubs.com"
    },
    {
      "name": "Eugeny Vlasenko",
      "email": "mahnunchik@gmail.com"
    },
    {
      "name": "Francesco Nero",
      "email": "nerofrancesco@hotmail.com"
    },
    {
      "name": "gabrielmancini",
      "email": "gabriel.mancini@gmail.com"
    },
    {
      "name": "Gary Pearman",
      "email": "gpearman@gmail.com"
    },
    {
      "name": "gazsp",
      "email": "gpearman@gmail.com"
    },
    {
      "name": "George",
      "email": "shankga@gmail.com"
    },
    {
      "name": "George Shank",
      "email": "shankga@gmail.com"
    },
    {
      "name": "Gustavo",
      "email": "guumaster@users.noreply.github.com"
    },
    {
      "name": "gustavo.marin",
      "email": "gustavo.marin@intelygenz.com"
    },
    {
      "name": "guumaster",
      "email": "gustavoandresmarin@gmail.com"
    },
    {
      "name": "guumaster",
      "email": "guuweb@gmail.com"
    },
    {
      "name": "Hüseyin BABAL",
      "email": "huseyinbabal88@gmail.com"
    },
    {
      "name": "Hüseyin BABAL",
      "email": "huseyin.babal@eu.sony.com"
    },
    {
      "name": "Ignacio Lago",
      "email": "ignacio@glue.gl"
    },
    {
      "name": "isayme",
      "email": "isaymeorg@gmail.com"
    },
    {
      "name": "jamescarr",
      "email": "jamescarr@VirtualBox.(none)",
      "url": "none"
    },
    {
      "name": "James Carr",
      "email": "james.r.carr@gmail.com"
    },
    {
      "name": "Alexandre-io",
      "email": "alexandre@gotoserv.com"
    },
    {
      "name": "James R. Carr",
      "email": "james.r.carr@gmail.com"
    },
    {
      "name": "Jason More",
      "email": "Jason.More@gmail.com"
    },
    {
      "name": "Jean-Baptiste Demonte",
      "email": "jbdemonte@gmail.com"
    },
    {
      "name": "jetNull",
      "email": "james.tuttle@matrixinsights.com"
    },
    {
      "name": "John Resig",
      "email": "jeresig@gmail.com"
    },
    {
      "name": "Jon Buckley",
      "email": "jon@jbuckley.ca"
    },
    {
      "name": "Jon Burgess",
      "email": "jon.burgess@bundlestars.com"
    },
    {
      "name": "Jon Burgess",
      "email": "jonjburgess@gmail.com"
    },
    {
      "name": "Jose Maza",
      "email": "jose.maza@rulesware.com"
    },
    {
      "name": "ksavidetove",
      "email": "kev1_2_tob@msn.com"
    },
    {
      "name": "Kyle Mathews",
      "email": "mathews.kyle@gmail.com"
    },
    {
      "name": "Marcos Sanz",
      "email": "marcos.sanz@13genius.com"
    },
    {
      "name": "Matt Audesse",
      "email": "matt@mattaudesse.com"
    },
    {
      "name": "Michael Hellein",
      "email": "themichaek@gmail.com"
    },
    {
      "name": "Nadeesha Cabral",
      "email": "nadeesha.cabral@gmail.com"
    },
    {
      "name": "Nicolas McCurdy",
      "email": "thenickperson@gmail.com"
    },
    {
      "name": "Nico Schlömer",
      "email": "nico.schloemer@gmail.com"
    },
    {
      "name": "nlko",
      "email": "nospam1@thomasson.fr"
    },
    {
      "name": "nvartolomei",
      "email": "nvartolomei@gmail.com"
    },
    {
      "name": "Phillip Rosen",
      "email": "phill.rosen@gmail.com"
    },
    {
      "name": "py09mb",
      "email": "py09mb@users.noreply.github.com"
    },
    {
      "name": "Renner",
      "email": "kai-uwe.renner@hbv83032616.bauer-de.bauermedia.group"
    },
    {
      "name": "Robert Katzki",
      "email": "robert@bildungsweb.net"
    },
    {
      "name": "root",
      "email": "root@helloo-dev.home"
    },
    {
      "name": "Ro Ramtohul",
      "email": "yoitsro@hotmail.com"
    },
    {
      "name": "Samy Pessé",
      "email": "samypesse@gmail.com"
    },
    {
      "name": "Sascha Schwabbauer",
      "email": "sascha@evolved.io"
    },
    {
      "name": "Srfrnk",
      "email": "srfrnk@gmail.com"
    },
    {
      "name": "stickycube",
      "email": "will.jk01@gmail.com"
    },
    {
      "name": "Sukru BEZEN",
      "email": "sukru@sukrubezen.com"
    },
    {
      "name": "taterbase",
      "email": "shankga@gmail.com"
    },
    {
      "name": "Vincent Boucher",
      "email": "vin.boucher@gmail.com"
    },
    {
      "name": "Warner Onstine",
      "email": "warner@clipppr.com"
    },
    {
      "name": "Will Knowles",
      "email": "will.jk01@gmail.com"
    },
    {
      "name": "xizhao",
      "email": "kevin.wang@cloudera.com"
    },
    {
      "name": "xren",
      "email": "rex@bittorrent.com"
    }
  ],
  "dependencies": {
    "elasticsearch": "13.3.0",
    "lodash.clonedeep": "4.5.0"
  },
  "deprecated": false,
  "description": "A mongoose plugin that indexes models into elastic search",
  "devDependencies": {
    "async": "2.5.0",
    "changelog": "^1.0.7",
    "co-mocha": "^1.1.3",
    "coveralls": "2.13.1",
    "eslint": "4.4.1",
    "eslint-config-standard": "6.2.1",
    "eslint-plugin-promise": "3.5.0",
    "eslint-plugin-standard": "3.0.1",
    "istanbul": "0.4.5",
    "mocha": "3.2.0",
    "mongoose": "4.11.8",
    "should": "12.0.0",
    "standard": "10.0.3"
  },
  "engines": {
    "node": ">= 4.0"
  },
  "homepage": "https://github.com/mongoosastic/mongoosastic#readme",
  "license": "MIT",
  "main": "lib/mongoosastic.js",
  "name": "mongoosastic",
  "optionalDependencies": {},
  "readme": "# Mongoosastic\n[![Build Status](https://travis-ci.org/mongoosastic/mongoosastic.svg?branch=master)](https://travis-ci.org/mongoosastic/mongoosastic)\n[![NPM version](https://img.shields.io/npm/v/mongoosastic.svg)](https://www.npmjs.com/package/mongoosastic)\n[![Coverage Status](https://coveralls.io/repos/mongoosastic/mongoosastic/badge.svg?branch=master&service=github)](https://coveralls.io/github/mongoosastic/mongoosastic?branch=master)\n[![Downloads](https://img.shields.io/npm/dm/mongoosastic.svg)](https://www.npmjs.com/package/mongoosastic)\n[![Gitter](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/mongoosastic/mongoosastic?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge)\n\n[![NPM](https://nodei.co/npm/mongoosastic.png)](https://nodei.co/npm/mongoosastic/)\n\nMongoosastic is a [mongoose](http://mongoosejs.com/) plugin that can automatically index your models into [elasticsearch](https://www.elastic.co/).\n\n- [Installation](#installation)\n- [Setup](#setup)\n- [Indexing](#indexing)\n  - [Saving a document](#saving-a-document)\n  - [Removing a document](#removing-a-document)\n  - [Indexing nested models](#indexing-nested-models)\n  - [Indexing mongoose references](#indexing-mongoose-references)\n  - [Indexing an existing collection](#indexing-an-existing-collection)\n  - [Bulk indexing](#bulk-indexing)\n  - [Filtered indexing](#filtered-indexing)\n  - [Indexing on demand](#indexing-on-demand)\n  - [Unindexing on demand](#unindexing-on-demand)\n  - [Truncating an index](#truncating-an-index)\n  - [Restrictions](#restrictions)\n    - [Auto indexing](#auto-indexing)\n    - [Search immediately after es-indexed event](#search-immediately-after-es-indexed-event)\n- [Mapping](#mapping)\n  - [Geo mapping](#geo-mapping)\n    - [Indexing a geo point](#indexing-a-geo-point)\n    - [Indexing a geo shape](#indexing-a-geo-shape)\n  - [Creating mappings on-demand](#creating-mappings-on-demand)\n- [Queries](#queries)\n  - [Hydration](#hydration)\n\n## Installation\n\nThe latest version of this package will be as close as possible to the latest `elasticsearch` and `mongoose` packages.\n\n```bash\nnpm install -S mongoosastic\n```\n\n## Setup\n\n### Model.plugin(mongoosastic, options)\n\nOptions are:\n\n* `index` - the index in Elasticsearch to use. Defaults to the pluralization of the model name.\n* `type`  - the type this model represents in Elasticsearch. Defaults to the model name.\n* `esClient` - an existing Elasticsearch `Client` instance.\n* `hosts` - an array hosts Elasticsearch is running on.\n* `host` - the host Elasticsearch is running on\n* `port` - the port Elasticsearch is running on\n* `auth` - the authentication needed to reach Elasticsearch server. In the standard format of 'username:password'\n* `protocol` - the protocol the Elasticsearch server uses. Defaults to http\n* `hydrate` - whether or not to lookup results in mongodb before\n* `hydrateOptions` - options to pass into hydrate function\n* `bulk` - size and delay options for bulk indexing\n* `filter` - the function used for filtered indexing\n* `transform` - the function used to transform serialized document before indexing\n* `populate` - an Array of Mongoose populate options objects\n* `indexAutomatically` - allows indexing after model save to be disabled for when you need finer control over when documents are indexed. Defaults to true\n* `customProperties` - an object detailing additional properties which will be merged onto the type's default mapping when `createMapping` is called.\n* `saveOnSynchronize` - triggers Mongoose save (and pre-save) method when synchronizing a collection/index. Defaults to true\n\n\nTo have a model indexed into Elasticsearch simply add the plugin.\n\n```javascript\nvar mongoose     = require('mongoose')\n  , mongoosastic = require('mongoosastic')\n  , Schema       = mongoose.Schema\n\nvar User = new Schema({\n    name: String\n  , email: String\n  , city: String\n})\n\nUser.plugin(mongoosastic)\n```\n\nThis will by default simply use the pluralization of the model name as the index\nwhile using the model name itself as the type. So if you create a new\nUser object and save it, you can see it by navigating to\nhttp://localhost:9200/users/user/_search (this assumes Elasticsearch is\nrunning locally on port 9200).\n\nThe default behavior is all fields get indexed into Elasticsearch. This can be a little wasteful especially considering that\nthe document is now just being duplicated between mongodb and\nElasticsearch so you should consider opting to index only certain fields by specifying `es_indexed` on the\nfields you want to store:\n\n\n```javascript\nvar User = new Schema({\n    name: {type:String, es_indexed:true}\n  , email: String\n  , city: String\n})\n\nUser.plugin(mongoosastic)\n```\n\nIn this case only the name field will be indexed for searching.\n\nNow, by adding the plugin, the model will have a new method called\n`search` which can be used to make simple to complex searches. The `search`\nmethod accepts [standard Elasticsearch query DSL](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-queries.html)\n\n```javascript\nUser.search({\n  query_string: {\n    query: \"john\"\n  }\n}, function(err, results) {\n  // results here\n});\n\n```\n\nTo connect to more than one host, you can use an array of hosts.\n\n```javascript\nMyModel.plugin(mongoosastic, {\n  hosts: [\n    'localhost:9200',\n    'anotherhost:9200'\n  ]\n})\n```\n\nAlso, you can re-use an existing Elasticsearch `Client` instance\n\n```javascript\nvar esClient = new elasticsearch.Client({host: 'localhost:9200'});\nMyModel.plugin(mongoosastic, {\n  esClient: esClient\n})\n```\n\n\n## Indexing\n\n### Saving a document\nThe indexing takes place after saving in mongodb and is a deferred process.\nOne can check the end of the indexation by catching the es-indexed event.\n\n```javascript\ndoc.save(function(err){\n  if (err) throw err;\n  /* Document indexation on going */\n  doc.on('es-indexed', function(err, res){\n    if (err) throw err;\n    /* Document is indexed */\n    });\n  });\n```\n\n### Removing a document\nRemoving a document, or unindexing, takes place when a document is removed by calling `.remove()` on a mongoose Document instance.\nOne can check the end of the unindexing by catching the es-removed event.\n\n```javascript\ndoc.remove(function(err) {\n  if (err) throw err;\n  /* Document unindexing in the background */\n  doc.on('es-removed', function(err, res) {\n    if (err) throw err;\n    /* Docuemnt is unindexed */\n  });\n});\n```\n\nNote that use of `Model.remove` does not involve mongoose documents as outlined in the [documentation](http://mongoosejs.com/docs/api.html#model_Model.remove). Therefore, the following will not unindex the document.\n\n```javascript\nMyModel.remove({ _id: doc.id }, function(err) {\n  /* doc remains in Elasticsearch cluster */\n});\n```\n\n### Indexing Nested Models\nIn order to index nested models you can refer following example.\n\n```javascript\nvar Comment = new Schema({\n    title: String\n  , body: String\n  , author: String\n})\n\n\nvar User = new Schema({\n    name: {type:String, es_indexed:true}\n  , email: String\n  , city: String\n  , comments: {type:[Comment], es_indexed:true}\n})\n\nUser.plugin(mongoosastic)\n```\n\n### Elasticsearch [Nested datatype](https://www.elastic.co/guide/en/elasticsearch/reference/current/nested.html)\nSince the default in Elasticsearch is to take arrays and flatten them into objects,\nit can make it hard to write queries where you need to maintain the relationships\nbetween objects in the array, per .\nThe way to change this behavior is by changing the Elasticsearch type from `object`\n(the mongoosastic default) to `nested`\n\n```javascript\nvar Comment = new Schema({\n    title: String\n  , body: String\n  , author: String\n})\n\n\nvar User = new Schema({\n    name: {type: String, es_indexed: true}\n  , email: String\n  , city: String\n  , comments: {\n      type:[Comment],\n      es_indexed: true,\n      es_type: 'nested',\n      es_include_in_parent: true\n  }\n})\n\nUser.plugin(mongoosastic)\n```\n\n### Indexing Mongoose References\nIn order to index mongoose references you can refer following example.\n\n```javascript\nvar Comment = new Schema({\n    title: String\n  , body: String\n  , author: String\n});\n\n\nvar User = new Schema({\n    name: {type:String, es_indexed:true}\n  , email: String\n  , city: String\n  , comments: {type: Schema.Types.ObjectId, ref: 'Comment',\n    es_schema: Comment, es_indexed:true, es_select: 'title body'}\n})\n\nUser.plugin(mongoosastic, {\n  populate: [\n    {path: 'comments', select: 'title body'}\n  ]\n})\n```\nIn the schema you'll need to provide `es_schema` field - the referenced schema.\nBy default every field of the referenced schema will be mapped. Use `es_select` field to pick just specific fields.\n\n`populate` is an array of options objects you normally pass to\n[Model.populate](http://mongoosejs.com/docs/api.html#model_Model.populate).\n\n### Indexing An Existing Collection\nAlready have a mongodb collection that you'd like to index using this\nplugin? No problem! Simply call the synchronize method on your model to\nopen a mongoose stream and start indexing documents individually.\n\n```javascript\nvar BookSchema = new Schema({\n  title: String\n});\nBookSchema.plugin(mongoosastic);\n\nvar Book = mongoose.model('Book', BookSchema)\n  , stream = Book.synchronize()\n  , count = 0;\n\nstream.on('data', function(err, doc){\n  count++;\n});\nstream.on('close', function(){\n  console.log('indexed ' + count + ' documents!');\n});\nstream.on('error', function(err){\n  console.log(err);\n});\n```\n\nYou can also synchronize a subset of documents based on a query!\n\n```javascript\nvar stream = Book.synchronize({author: 'Arthur C. Clarke'})\n```\n\nAs well as specifying synchronization options\n\n```javascript\nvar stream = Book.synchronize({}, {saveOnSynchronize: true})\n```\n\nOptions are:\n\n * `saveOnSynchronize` - triggers Mongoose save (and pre-save) method when synchronizing a collection/index. Defaults to global `saveOnSynchronize` option\n\n\n### Bulk Indexing\n\nYou can also specify `bulk` options with mongoose which will utilize Elasticsearch's bulk indexing api. This will cause the `synchronize` function to use bulk indexing as well.\n\nMongoosastic will wait 1 second (or specified delay) until it has 1000 docs (or specified size) and then perform bulk indexing.\n\n```javascript\nBookSchema.plugin(mongoosastic, {\n  bulk: {\n    size: 10, // preferred number of docs to bulk index\n    delay: 100 //milliseconds to wait for enough docs to meet size constraint\n  }\n});\n```\n\n### Filtered Indexing\n\nYou can specify a filter function to index a model to Elasticsearch based on some specific conditions.\n\nFiltering function must return True for conditions that will ignore indexing to Elasticsearch.\n\n```javascript\nvar MovieSchema = new Schema({\n  title: {type: String},\n  genre: {type: String, enum: ['horror', 'action', 'adventure', 'other']}\n});\n\nMovieSchema.plugin(mongoosastic, {\n  filter: function(doc) {\n    return doc.genre === 'action';\n  }\n});\n```\n\nInstances of Movie model having 'action' as their genre will not be indexed to Elasticsearch.\n\n\n### Indexing On Demand\nYou can do on-demand indexes using the `index` function\n\n```javascript\nDude.findOne({name:'Jeffrey Lebowski', function(err, dude){\n  dude.awesome = true;\n  dude.index(function(err, res){\n    console.log(\"egads! I've been indexed!\");\n  });\n});\n```\n\nThe index method takes 2 arguments:\n\n* `options` (optional) - {index, type} - the index and type to publish to. Defaults to the standard index and type that\n  the model was setup with.\n* `callback` - callback function to be invoked when document has been\n  indexed.\n\nNote that indexing a model does not mean it will be persisted to\nmongodb. Use save for that.\n\n### Unindexing on demand\nYou can remove a document from the Elasticsearch cluster by using the `unIndex` function.\n\n```javascript\ndoc.unIndex(function(err) {\n  console.log(\"I've been removed from the cluster :(\");\n});\n```\n\nThe unIndex method takes 2 arguments:\n\n* `options` (optional) - {index, type} - the index and type to publish to. Defaults to the standard index and type that\n  the model was setup with.\n* `callback` - callback function to be invoked when model has been\n  unindexed.\n\n\n### Truncating an index\n\nThe static method `esTruncate` will delete all documents from the associated index. This method combined with `synchronize()` can be useful in case of integration tests for example when each test case needs a cleaned up index in Elasticsearch.\n\n```javascript\nGarbageModel.esTruncate(function(err){...});\n```\n\n### Restrictions\n\n#### Auto indexing\n\nMongoosastic try to auto index documents in favor of mongoose's [middleware](http://mongoosejs.com/docs/middleware.html) feature.\n\nMongoosastic will auto index when `document.save`/`Model.findOneAndUpdate`/`Model.insertMany`/`document.remove`/`Model.findOneAndRemove`, but not include `Model.remove`/`Model.update`.\n\nAnd you should have `new: true` options when `findOneAndUpdate` so that mongoosastic can get new values in post hook.\n\n#### Search immediately after es-indexed event\n\n> Elasticsearch by default refreshes each shard every 1s, so the document will be available to search 1s after indexing it.\n\nThe event `es-indexed` means that elasticsearch received the index request, and if you want to search the document, please try after 1s. See [Document not found immediately after it is saved ](https://github.com/elastic/elasticsearch-js/issues/231)\n\n## Mapping\n\nSchemas can be configured to have special options per field. These match\nwith the existing [field mapping configurations](https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-types.html) defined by Elasticsearch with the only difference being they are all prefixed by \"es_\".\n\nSo for example. If you wanted to index a book model and have the boost\nfor title set to 2.0 (giving it greater priority when searching) you'd\ndefine it as follows:\n\n```javascript\nvar BookSchema = new Schema({\n    title: {type:String, es_boost:2.0}\n  , author: {type:String, es_null_value:\"Unknown Author\"}\n  , publicationDate: {type:Date, es_type:'date'}\n});\n\n```\nThis example uses a few other mapping fields... such as null_value and\ntype (which overrides whatever value the schema type is, useful if you\nwant stronger typing such as float).\n\nThere are various mapping options that can be defined in Elasticsearch. Check out [https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping.html) for more information. Here are examples to the currently possible definitions in mongoosastic:\n\n```javascript\nvar ExampleSchema = new Schema({\n  // String (core type)\n  string: {type:String, es_boost:2.0},\n\n  // Number (core type)\n  number: {type:Number, es_type:'integer'},\n\n  // Date (core type)\n  date: {type:Date, es_type:'date'},\n\n  // Array type\n  array: {type:Array, es_type:'string'},\n\n  // Object type\n  object: {\n    field1: {type: String},\n    field2: {type: String}\n  },\n\n  // Nested type\n  nested: [SubSchema],\n\n  // Multi field type\n  multi_field: {\n    type: String,\n    es_type: 'multi_field',\n    es_fields: {\n      multi_field: { type: 'string', index: 'analyzed' },\n      untouched: { type: 'string', index: 'not_analyzed' }\n    }\n  },\n\n  // Geo point type\n  geo: {\n    type: String,\n    es_type: 'geo_point'\n  },\n\n  // Geo point type with lat_lon fields\n  geo_with_lat_lon: {\n    geo_point: {\n      type: String,\n      es_type: 'geo_point',\n      es_lat_lon: true\n    },\n    lat: { type: Number },\n    lon: { type: Number }\n  }\n\n  geo_shape: {\n    coordinates : [],\n    type: {type: String},\n    geo_shape: {\n      type:String,\n      es_type: \"geo_shape\",\n      es_tree: \"quadtree\",\n      es_precision: \"1km\"\n    }\n  }\n\n  // Special feature : specify a cast method to pre-process the field before indexing it\n  someFieldToCast : {\n    type: String,\n    es_cast: function(value){\n      return value + ' something added';\n    }\n  }\n\n});\n\n// Used as nested schema above.\nvar SubSchema = new Schema({\n  field1: {type: String},\n  field2: {type: String}\n});\n```\n\n### Geo mapping\nPrior to index any geo mapped data (or calling the synchronize),\nthe mapping must be manualy created with the createMapping (see above).\n\nNotice that the name of the field containing the ES geo data must start by\n'geo_' to be recognize as such.\n\n#### Indexing a geo point\n\n```javascript\nvar geo = new GeoModel({\n  /* … */\n  geo_with_lat_lon: { lat: 1, lon: 2}\n  /* … */\n});\n```\n\n#### Indexing a geo shape\n\n```javascript\nvar geo = new GeoModel({\n  …\n  geo_shape:{\n    type:'envelope',\n    coordinates: [[3,4],[1,2] /* Arrays of coord : [[lon,lat],[lon,lat]] */\n  }\n  …\n});\n```\n\nMapping, indexing and searching example for geo shape can be found in test/geo-test.js\n\nFor example, one can retrieve the list of document where the shape contain a specific\npoint (or polygon...)\n\n```javascript\nvar geoQuery = {\n      \"match_all\": {}\n    }\n\nvar geoFilter = {\n      geo_shape: {\n        geo_shape: {\n          shape: {\n            type: \"point\",\n            coordinates: [3,1]\n          }\n        }\n      }\n    }\n\nGeoModel.search(geoQuery, {filter: geoFilter}, function(err, res) { /* ... */ })\n```\n\n### Creating Mappings On Demand\nCreating the mapping is a **one time operation** and **should be called manualy**.\n\nA BookSchema as an example:\n\n```javascript\nvar BookSchema = new Schema({\n    title: {type:String, es_boost:2.0}\n  , author: {type:String, es_null_value:\"Unknown Author\"}\n  , publicationDate: {type:Date, es_type:'date'}\n\nBookSchema.plugin(mongoosastic);\nvar Book = mongoose.model('Book', BookSchema);\nBook.createMapping({\n  \"analysis\" : {\n    \"analyzer\":{\n      \"content\":{\n        \"type\":\"custom\",\n        \"tokenizer\":\"whitespace\"\n      }\n    }\n  }\n},function(err, mapping){\n  // do neat things here\n});\n\n```\nThis feature is still a work in progress. As of this writing you'll have\nto manage whether or not you need to create the mapping, mongoosastic\nwill make no assumptions and simply attempt to create the mapping. If\nthe mapping already exists, an Exception detailing such will be\npopulated in the `err` argument.\n\n\n## Queries\nThe full query DSL of Elasticsearch is exposed through the search\nmethod. For example, if you wanted to find all people between ages 21\nand 30:\n\n```javascript\nPerson.search({\n  range: {\n    age:{\n      from:21\n    , to: 30\n    }\n  }\n}, function(err, people){\n   // all the people who fit the age group are here!\n});\n\n```\nSee the Elasticsearch [Query DSL](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html) docs for more information.\n\nYou can also specify query options like [sorts](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-sort.html#search-request-sort)\n\n```javascript\nPerson.search({/* ... */}, {sort: \"age:asc\"}, function(err, people){\n  //sorted results\n});\n```\n\nAnd also [aggregations](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations.html):\n\n```javascript\nPerson.search({/* ... */}, {\n  aggs: {\n    'names': {\n      'terms': {\n        'field': 'name'\n      }\n    }\n  }\n}, function(err, results){\n  // results.aggregations holds the aggregations\n});\n```\n\nOptions for queries must adhere to the [javascript elasticsearch driver specs](https://www.elastic.co/guide/en/elasticsearch/client/javascript-api/current/api-reference.html#api-search).\n\n### Raw queries\nA full ElasticSearch query object can be provided to mongoosastic through `.esSearch()` method.\nIt can be useful when paging results. The query to be provided wraps the query object provided to `.search()` method and\naccepts the same options:\n\n```javascript\nvar rawQuery = {\n    from: 60,\n    size: 20,\n    query: /* query object as in .search() */\n};\n\nModel.esSearch(rawQuery, options, cb);\n```\n\nFor example:\n\n```javascript\nPerson.esSearch({\n  from: 60,\n  size: 20,\n  query: {\n    range: {\n      age:{\n        from:21,\n        to: 30\n      }\n    }\n  }\n}, function(err, people){\n   // only the 61st to 80th ranked people who fit the age group are here!\n});\n```\n\n### Hydration\nBy default objects returned from performing a search will be the objects\nas is in Elasticsearch. This is useful in cases where only what was\nindexed needs to be displayed (think a list of results) while the actual\nmongoose object contains the full data when viewing one of the results.\n\nHowever, if you want the results to be actual mongoose objects you can\nprovide {hydrate:true} as the second argument to a search call.\n\n```javascript\n\nUser.search(\n  {query_string: {query: 'john'}},\n  {hydrate: true},\n  function(err, results) {\n    // results here\n});\n\n```\n\nYou can also pass in a `hydrateOptions` object with information on\nhow to query for the mongoose object.\n\n```javascript\n\nUser.search(\n  {query_string: {query: 'john'}},\n  {\n    hydrate: true,\n    hydrateOptions: {select: 'name age'}\n  },\n  function(err, results) {\n    // results here\n});\n\n```\n\nOriginal ElasticSearch result data can be kept with `hydrateWithESResults` option. Documents are then enhanced with a\n`_esResult` property\n\n```javascript\n\nUser.search(\n  {query_string: {query: 'john'}},\n  {\n    hydrate: true,\n    hydrateWithESResults: true,\n    hydrateOptions: {select: 'name age'}\n  },\n  function(err, results) {\n    // results here\n    results.hits.hits.forEach(function(result) {\n      console.log(\n        'score',\n        result._id,\n        result._esResult._score\n      );\n    });\n});\n\n```\n\nBy default the `_esResult._source` document is skipped. It can be added with the option `hydrateWithESResults: {source: false}`.\n\n\n\nNote using hydrate will be a degree slower as it will perform an Elasticsearch\nquery and then do a query against mongodb for all the ids returned from\nthe search result.\n\nYou can also default this to always be the case by providing it as a\nplugin option (as well as setting default hydrate options):\n\n\n```javascript\nvar User = new Schema({\n    name: {type:String, es_indexed:true}\n  , email: String\n  , city: String\n})\n\nUser.plugin(mongoosastic, {hydrate:true, hydrateOptions: {lean: true}})\n```\n",
  "readmeFilename": "README.md",
  "repository": {
    "type": "git",
    "url": "git://github.com/mongoosastic/mongoosastic.git"
  },
  "scripts": {
    "authors": "./scripts/update_authors.sh",
    "changelog": "changelog mongoosastic/mongoosastic latest -m",
    "coverage": "cat ./coverage/lcov.info | coveralls",
    "lint": "eslint lib test",
    "mocha": "mocha test/*-test.js",
    "test": "npm run lint && istanbul cover _mocha --report lcovonly -- test/*-test.js"
  },
  "tags": [
    "elastic search",
    "elasticsearch",
    "full text search",
    "mongodb",
    "mongoose"
  ],
  "version": "4.4.1"
}
